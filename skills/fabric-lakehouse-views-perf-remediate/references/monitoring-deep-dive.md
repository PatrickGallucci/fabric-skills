# Monitoring Deep Dive for Materialized Lake Views

## Table of Contents

- [Monitor Hub Navigation](#monitor-hub-navigation)
- [Filtering and Searching MLV Runs](#filtering-and-searching-mlv-runs)
- [Run Detail Panel](#run-detail-panel)
- [Spark Log Analysis](#spark-log-analysis)
- [Data Quality Report](#data-quality-report)
- [API-Based Monitoring](#api-based-monitoring)
- [Interpreting Run States](#interpreting-run-states)
- [Performance Baselines](#performance-baselines)

---

## Monitor Hub Navigation

Access Monitor Hub from the Fabric navigation bar. MLV runs appear with the activity name pattern:

```
MLV_LakehouseName_JobInstanceID
```

The Job Type for MLV runs is **MaterializedLakeViews**. Use this to filter specifically for MLV activity.

## Filtering and Searching MLV Runs

### Available Filters

| Filter | Values | Usage |
|--------|--------|-------|
| Status | Completed, Failed, In Progress, Canceled | Narrow to problem runs |
| Item Type | Lakehouse | MLV runs are associated with their parent lakehouse |
| Job Type | MaterializedLakeViews | Filter to only MLV-related jobs |
| Start Time | Date range | Identify recent failures or performance changes |
| Submitter | User or system | Distinguish manual vs scheduled runs |
| Location | Workspace | Filter by workspace in multi-workspace setups |

### Sorting Options

Sort by any column header: Name, Status, Job Instance ID, Job Type, Start Time, Location.

### Search

Enter keywords in the search box. Match against activity name, which follows the `MLV_LakehouseName_JobInstanceID` pattern.

## Run Detail Panel

Hover over an MLV run row and click **View details** to open the Detail pane.

**Available Information:**

- Run start and end times
- Duration
- Status
- Associated environment (if accessible)
- Job Instance ID

Click the activity name to navigate to the lineage view for that specific run (works for both in-progress and completed runs).

## Spark Log Analysis

When a node fails in the lineage view:

1. Click the failed node to see the error summary in the right panel
2. Click **Detailed Logs** to navigate to Monitor Hub
3. In Monitor Hub, access the Spark application logs

### What to Look For in Spark Logs

| Log Pattern | Indicates | Action |
|-------------|-----------|--------|
| `java.lang.OutOfMemoryError` | Insufficient executor memory | Increase memory in custom environment |
| `AnalysisException: Table not found` | Source table missing or renamed | Verify source table exists; check schema name casing |
| `delta table not found` | Known issue with FAIL constraints | Recreate MLV with DROP action |
| `SparkException: Job aborted` | General Spark failure | Check executor logs for root cause |
| `FileNotFoundException` | Delta log files missing | Run table maintenance (OPTIMIZE/VACUUM) on source |
| `ClassNotFoundException` | Missing library in environment | Add required library to custom environment |
| Timeout errors | Long-running operations | Optimize query, add partitioning, or increase resources |

## Data Quality Report

Access the autogenerated data quality report:

1. Navigate to Manage materialized lake views
2. Click **Data quality report** button in the ribbon

The report shows:

- Constraint violations per MLV
- Count of dropped records (for DROP action constraints)
- Constraint names and conditions

Use this to identify if data quality issues are degrading performance (high DROP counts indicate noisy source data).

## API-Based Monitoring

MLV supports monitoring via Fabric REST APIs. Use these endpoints for programmatic monitoring:

### List Job Instances

```
GET https://api.fabric.microsoft.com/v1/workspaces/{workspaceId}/items/{lakehouseId}/jobs/instances
```

### Get Specific Job Instance

```
GET https://api.fabric.microsoft.com/v1/workspaces/{workspaceId}/items/{lakehouseId}/jobs/instances/{jobInstanceId}
```

### Known API Limitations

- Job status from API reflects Monitor Hub status, which may differ from MLV lineage run history (e.g., "Skipped" shows as "Canceled" in Monitor Hub)
- Limited number of completed/active jobs displayed
- Service principal authentication NOT supported; use Microsoft Entra user tokens

## Interpreting Run States

### State Transition Flow

```
Scheduled
    |
    v
In Progress --> Completed (all nodes succeeded)
    |        \-> Failed (any node failed; children skipped)
    |        \-> Canceled (user canceled from Monitor Hub)
    v
Skipped (previous run still in progress)
```

### Key State Details

**Completed:** All nodes in the lineage executed successfully. Check the data quality report for any dropped records.

**Failed:** At least one node failed. All child (dependent) nodes are automatically Skipped. Always fix the root failure first before re-running.

**Skipped:** The scheduled trigger fired while a previous run was still in progress. This is normal for overlapping schedules. Reduce schedule frequency or optimize refresh duration.

**In Progress:** The run is actively executing. Individual node status may vary (some completed, some pending).

**Canceled:** A user manually canceled the run from Monitor Hub. This stops the current node and skips all remaining nodes.

## Performance Baselines

Establish baselines by tracking these metrics over time:

| Metric | How to Measure | Target |
|--------|---------------|--------|
| Total refresh duration | End time minus start time in run history | Consistent or improving |
| Per-node duration | Click individual nodes for timing details | No single node dominates |
| Refresh strategy | Check if incremental or full in Spark logs | Incremental when expected |
| Dropped record count | Data quality report | Stable or decreasing |
| Failure rate | Count of Failed runs vs Completed | < 5% failure rate |

### Setting Up Alerts

While MLV does not have built-in alerting, you can:

1. Use the Fabric REST API to poll job status programmatically
2. Build a Power Automate flow that checks MLV run status on schedule
3. Create a monitoring notebook that queries run history and sends notifications

### Run History Retention

- Last 25 runs are available in the lineage dropdown
- Alternatively, runs from the last 7 days (whichever comes first)
- Environment details shown only if user has access and the environment still exists
